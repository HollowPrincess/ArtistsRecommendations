{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Network_matrix_with_tags_likes_etc.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1hU2NPgo7aVHQbFEo3IRRUUIxaXXYj8s_","authorship_tag":"ABX9TyNPVQ1CmolQdtZptO07dme4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-8ipw2TEzWcG","colab_type":"text"},"source":["Здесь происходит обучение и оценка нейросети."]},{"cell_type":"code","metadata":{"id":"hMXDkDpRwQDN","colab_type":"code","outputId":"c7135d5d-b3e5-4566-fde4-d27ac225c9a7","executionInfo":{"status":"ok","timestamp":1592313981452,"user_tz":-180,"elapsed":14183,"user":{"displayName":"Света Сорокина","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhP5b7WHhwRcbIn8yB21S2mZi9tlMCD4aFLmFcr=s64","userId":"00408643672459262753"}},"colab":{"base_uri":"https://localhost:8080/","height":836}},"source":["!pip install tensorflow\n","!pip install ml_metrics\n","!pip install nptyping"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.2)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.29.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n","Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (47.1.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n","Requirement already satisfied: ml_metrics in /usr/local/lib/python3.6/dist-packages (0.1.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ml_metrics) (1.0.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ml_metrics) (1.18.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->ml_metrics) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->ml_metrics) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->ml_metrics) (1.12.0)\n","Requirement already satisfied: nptyping in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: typish>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from nptyping) (1.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nptyping) (1.18.5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G20Vo5UBCjK9","colab_type":"text"},"source":["На выходе такая сеть дает вероятностное распределение по множеству рекомендованных видео. При обучении необходимо в качестве выхода задать возможные распределения для сети. В качестве таких распределений было решено взять долю пользователей, слушающих исполнителя, для которого составлен вектор, и исполнителей из множества для рекомендаций.\n","При таком представлении нет смысла в качестве фич подавать матрицу смежности, рассмотренную длякластеризации, так как по факту на выходе будет она же, только нормированная по строкам, поэтому рассматриваются остальные признаки.\n"]},{"cell_type":"code","metadata":{"id":"-rhI1tdpttIN","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import Normalizer\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.model_selection import train_test_split\n","from scipy.sparse import csr_matrix, load_npz\n","import ml_metrics\n","from nptyping import NDArray\n","from typing import Any, Dict\n","import re\n","import sys\n","import tensorflow as tf\n","import math\n","\n","DATA_DIR = './drive/My Drive/Colab Notebooks/VK_internship/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U29a56TcWPQz","colab_type":"code","colab":{}},"source":["def get_network_recommendations_and_calculate_metrics(\n","    logits, \n","    user_artists_df: pd.DataFrame(columns=[\"user_id\", \"artists\"]), \n","    test: NDArray[(Any,), int],\n","    artists_idxs_for_rec: NDArray[(1000,), int]\n",") -> Dict[int, float]:\n","    \"\"\"\n","    Извечение рекомендаций из распределений, оценка качества рекомендаций.\n","    \"\"\"\n","    metrics = {}\n","    for k in [1,5,10,20]:\n","        metrics[k]=0\n","\n","    for artist_id, artist_logit in zip(test, logits):\n","        top21col_id = np.argpartition(artist_logit, -21)[-21:]\n","        recommend = artists_idxs_for_rec[list(top21col_id)]\n","        # Поиск списков исполнителей, которых слушают те же пользователи, \n","        # что и artist_id:\n","        users = np.unique(user_artists_df.loc[user_artists_df[\"artists\"]==artist_id, \"user_id\"].values)\n","        similar_artists = user_artists_df.loc[user_artists_df[\"user_id\"].isin(users), \"artists\"].drop_duplicates().values\n","        similar_artists = similar_artists[similar_artists!=artist_id]\n","\n","        # Подсчет метрик качества\n","        for key in metrics.keys():\n","            metrics[key] += ml_metrics.apk(\n","                actual=list(similar_artists),\n","                predicted=list(recommend[:key]),\n","                k=key\n","            )\n","    return metrics\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5XeamJz79Vtq","colab_type":"text"},"source":["В качестве признаков используется сжатая информация (SVD) о лайках, тегах и плейлистах. Информация сильно сжата из-за ограничений дискового пространства (Google диск предоставляет всего 15 Гб).\n","Было бы неплохо попробовать определить оптимальное знаение для SVD, но на это потребуется очень много времени.\n","Также было бы неплохо попробовать эи фичи для KMeans."]},{"cell_type":"code","metadata":{"id":"j0NOHpQGRiXK","colab_type":"code","colab":{}},"source":["user_artists_df = pd.read_csv(DATA_DIR+\"users_artists.csv\", usecols=[\"user_id\", \"artists\"]).drop_duplicates()\n","artists_id = user_artists_df[\"artists\"].unique()\n","artists_id.sort()\n","train, test = train_test_split(artists_id, test_size=0.1)\n","del artists_id\n","\n","partial_user_artists_df = user_artists_df.loc[user_artists_df[\"artists\"].isin(train)]\n","partial_artists = partial_user_artists_df.groupby(\"artists\").count().reset_index()\n","partial_artists = partial_artists.sort_values(by=\"user_id\", ascending = False)\n","partial_artists_rows = partial_artists.loc[:,\"artists\"].values\n","partial_artists = partial_artists_rows[:1000]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xDJJlZghQ62e","colab_type":"text"},"source":["На выходе такая сеть дает вероятностное распределение по множеству рекомендованных видео. При обучении необходимо в качестве выхода задать возможные распределения для сети. В качестве таких распределений было решено взять долю пользователей, слушающих исполнителя, для которого составлен вектор, и исполнителей из множества для рекомендаций.\n","При таком представлении нет смысла в качестве фич подавать матрицу смежности, рассмотренную длякластеризации, так как по факту на выходе будет она же, только нормированная по строкам, поэтому рассматриваются остальные признаки."]},{"cell_type":"code","metadata":{"id":"p5VGY2V2KrWw","colab_type":"code","colab":{}},"source":["likes_matrix = np.loadtxt(DATA_DIR+\"likes_matrix.csv\")\n","playlists_matrix = np.loadtxt(DATA_DIR+\"playlists_matrix.csv\")\n","full_matrix = np.hstack((likes_matrix, playlists_matrix))\n","del likes_matrix, playlists_matrix\n","user_tags_matrix = np.loadtxt(DATA_DIR+\"user_tags_matrix.csv\")\n","full_matrix = np.hstack((full_matrix, user_tags_matrix))\n","del user_tags_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7KtBSwY5b06F","colab_type":"code","colab":{}},"source":["user_artists_df = pd.read_csv(DATA_DIR+\"users_artists.csv\", usecols=[\"user_id\", \"artists\"]).drop_duplicates()\n","artists_id = user_artists_df[\"artists\"].unique()\n","artists_id.sort()\n","train, test = train_test_split(artists_id, test_size=0.1)\n","del artists_id\n","partial_user_artists_df = user_artists_df.loc[user_artists_df[\"artists\"].isin(train)]\n","partial_artists = partial_user_artists_df.groupby(\"artists\").count().reset_index()\n","partial_artists = partial_artists.sort_values(by=\"user_id\", ascending = False)\n","partial_artists = partial_artists.loc[:,\"artists\"].values\n","partial_artists = partial_artists[:1000]\n","# строки в матрице вероятности отсортированы по популярности пользователей, это надо исправить"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DIntgYKcayqa","colab_type":"code","colab":{}},"source":["train_probabilities_matrix = load_npz(DATA_DIR+\"train_matrix.npz\") # y \n","train_probabilities_matrix = Normalizer(\"l1\").fit_transform(train_probabilities_matrix) \n","# нормализация строк от 0 до 1, чтобы было похоже на распределение вероятностей"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBm8J5TicwVj","colab_type":"code","colab":{}},"source":["train_matrix = full_matrix[partial_artists_rows,:]\n","train_matrix = train_matrix[:train_probabilities_matrix.shape[0],:]\n","test_matrix = full_matrix[test, :]\n","del full_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pe85goUILPG5","colab_type":"text"},"source":["Х - векторные представления, \n","\n","у - распределения вероятностей, основанное на взаимодействиях пользователей "]},{"cell_type":"code","metadata":{"id":"5O8zGwjtdZWg","colab_type":"code","colab":{}},"source":["vector_length = train_matrix.shape[1]\n","recommended_artists_amount = train_probabilities_matrix.shape[1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tMAZQj3zTf28","colab_type":"code","colab":{}},"source":["the_least_elem = np.min([np.min(train_matrix), np.min(test_matrix)])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AqJIjjqoCILJ","colab_type":"code","colab":{}},"source":["train_matrix = train_matrix-the_least_elem #make positive"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4U0t6uReasfH","colab_type":"text"},"source":["Чтобы попробовать исправить внутренние ошибки, возникающие при предсказании модели, было принято решение упростить модель, поэтому слои имеют размерность 64 в отличии от статьи, где размерность составляет 256."]},{"cell_type":"code","metadata":{"id":"hKqs7waMUHRQ","colab_type":"code","colab":{}},"source":["with tf.device('/GPU:0'):\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.Embedding(input_dim=int(math.ceil(np.max([np.max(train_matrix), np.max(test_matrix)])))+1, \n","                                        input_length=vector_length,\n","                                        output_dim=64))\n","    model.add(tf.keras.layers.Dense(64, activation='relu'))\n","    model.add(tf.keras.layers.GRU(64, dropout=0.1))\n","    model.add(tf.keras.layers.Dense(64, activation='relu'))\n","    model.add(tf.keras.layers.Dense(recommended_artists_amount, activation='softmax'))\n","    model.compile(optimizer=\"AdaGrad\", loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQiGWmaQV4HE","colab_type":"code","colab":{}},"source":["train_probabilities_matrix = csr_matrix(train_probabilities_matrix)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D4M3SlaD-CaN","colab_type":"text"},"source":["Обучение по батчам:"]},{"cell_type":"code","metadata":{"id":"H_SlkOMzUTxw","colab_type":"code","colab":{}},"source":["batch_size = 1000\n","batches_amunt = int(math.ceil(train_matrix.shape[0]/batch_size))\n","with tf.device('/GPU:0'):\n","    for batch_counter in range(batches_amunt):\n","        train_y = train_probabilities_matrix[batch_counter*batch_size:(batch_counter+1)*batch_size].toarray()\n","        train_x = train_matrix[batch_counter*batch_size:(batch_counter+1)*batch_size, :]\n","\n","        model.train_on_batch(x=train_x, y=train_y)\n","        model.save(DATA_DIR + 'recommendational_network.h5')\n","        print(batch_counter)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KGLXhD4_YykL","colab_type":"code","colab":{}},"source":["model = tf.keras.models.load_model(DATA_DIR + 'recommendational_network.h5')\n","test_matrix = test_matrix-the_least_elem"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"86VDzQ8U-Gke","colab_type":"text"},"source":["Метрики:"]},{"cell_type":"markdown","metadata":{"id":"Yw3zLzQvsBAJ","colab_type":"text"},"source":["В ходе выполнения возникли ошибки, на исправление времени не хватило, так как опыт работы с tensorflow у меня невелик."]},{"cell_type":"code","metadata":{"id":"JGR9IA7lfk99","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":472},"outputId":"61efa626-ef98-4ed5-e51c-85c8493157d4","executionInfo":{"status":"error","timestamp":1592319998114,"user_tz":-180,"elapsed":2365035,"user":{"displayName":"Света Сорокина","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhP5b7WHhwRcbIn8yB21S2mZi9tlMCD4aFLmFcr=s64","userId":"00408643672459262753"}}},"source":["metrics = {}\n","for k in [1,5,10,20]:\n","    metrics[k]=0\n","\n","batch_size = 1000\n","batches_amount = int(math.ceil(train_matrix.shape[0]/batch_size))+1\n","\n","\n","for batch_counter in range(batches_amount):\n","    logits = model(test_matrix[batch_counter*batch_size:(batch_counter+1)*batch_size, :])\n","    batch_metrics = get_network_recommendations_and_calculate_metrics(\n","            logits, \n","            user_artists_df, \n","            test[batch_counter*batch_size:(batch_counter+1)*batch_size],\n","            partial_artists\n","    )\n","    for key in metrics.keys():\n","          metrics[key]+=batch_metrics[key]"],"execution_count":18,"outputs":[{"output_type":"error","ename":"UnknownError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn\u001b[0;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mrnn_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_mode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"direction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dropout\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         dropout, \"seed\", seed, \"seed2\", seed2, \"is_training\", is_training)\n\u001b[0m\u001b[1;32m     92\u001b[0m       \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CudnnRNNOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31m_FallbackException\u001b[0m: Expecting float value for attr dropout, got int","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-35c870aca333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_counter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches_amount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_counter\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_counter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     batch_metrics = get_network_recommendations_and_calculate_metrics(\n\u001b[1;32m     12\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    717\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    718\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0;32m--> 438\u001b[0;31m           inputs, initial_state, training, mask, row_lengths)\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_defun_gru_call\u001b[0;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# Under eager context, check the device placement and prefer the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcan_use_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mgpu_gru_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnormal_gru_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mgpu_gru\u001b[0;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths)\u001b[0m\n\u001b[1;32m    655\u001b[0m     outputs, h, _, _ = gen_cudnn_rnn_ops.cudnn_rnn(\n\u001b[1;32m    656\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_c\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         rnn_mode='gru')\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m   \u001b[0mlast_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn\u001b[0;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0minput_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             ctx=_ctx)\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn_eager_fallback\u001b[0;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx)\u001b[0m\n\u001b[1;32m    177\u001b[0m   \"is_training\", is_training)\n\u001b[1;32m    178\u001b[0m   _result = _execute.execute(b\"CudnnRNN\", 4, inputs=_inputs_flat,\n\u001b[0;32m--> 179\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m    180\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     _execute.record_gradient(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnknownError\u001b[0m: CUDNN_STATUS_BAD_PARAM\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1459): 'cudnnSetTensorNdDescriptor( tensor_desc.get(), data_type, sizeof(dims) / sizeof(dims[0]), dims, strides)' [Op:CudnnRNN]"]}]},{"cell_type":"code","metadata":{"id":"HAjyN7CFfy3F","colab_type":"code","colab":{}},"source":["for key in metrics.keys():\n","    metrics[key]/=len(test)\n","    print(\"MAP@{}: \".format(key), metrics[key])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nx7y-xoahDwm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}